{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\n# import numpy as np\n# import os\n# import copy\nimport tensorflow as tf\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# from sklearn.metrics import classification_report,confusion_matrix\nimport keras\n# from keras.models import Sequential, Model,load_model\n# # from keras.preprocessing import image\n# import random\n# import numpy as np\n# from keras.layers import InputSpec,Layer,Input, Dense, BatchNormalization,Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation, Lambda, GlobalAveragePooling2D\n# # from keras.layers.normalization import BatchNormalization\n# from keras import backend as K\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport keras.backend as K\n\nfrom keras import initializers\nfrom keras.layers import Input,Layer,InputSpec\nfrom keras.layers import Dense\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import AveragePooling2D\nfrom keras.layers import ZeroPadding2D\nfrom keras.layers import Flatten\nfrom keras.layers import Activation\nfrom keras.layers import add\nfrom keras.layers import BatchNormalization\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import GlobalMaxPooling2D\n\nfrom keras.models import Model\n# from keras.engine import get_source_inputs\n\nfrom keras.utils import get_source_inputs\n\n\nfrom keras.utils.data_utils import get_file\nfrom keras_applications.imagenet_utils import _obtain_input_shape\ncategories = ['dew','fogsmog','frost','glaze','hail','lightning','rain','rainbow','rime','sandstorm','snow']\ndirectory=\"../input/nn22-weather-analysis-using-image-recognition/Dataset/Train\"\n#Now we can easily fetch our train and validation data.\ndata=[]\nfor category in categories:\n    folder = os.path.join(directory,category)\n    label=categories.index(category)\n    for img in os.listdir(folder):\n        img_path = os.path.join(folder,img)\n        #print(img_path)\n        img_arr= cv2.imread(img_path)\n        if img_arr is not None:\n            img_arr= (img_arr)[...,::-1]\n            #, alpha=0,beta=255\n            img_arr=cv2.normalize(img_arr, None, alpha=0,beta=255,norm_type=cv2.NORM_MINMAX)\n            img_arr= cv2.resize(img_arr,(224,224))\n            data.append([img_arr,label])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install google_images_download\n!pip install bing-image-downloader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from simple_image_download import simple_image_download as simp \nresponse = simp.simple_image_download\n\nlst=['dew plants', 'fogsmog sky', 'frost plants','glaze trees','hail','lightning sky','rain streets','rain','rainbow sky','rime trees','sandstorm weather','snow weather']\n\nfor rep in lst:\n    response().download(rep , 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def img_download(path, limit, keyword, format):\n    \n    \"\"\"\n    This function uses google_images_download library to download the images.\n    \n    If you want to download more than 100 images you need chromedriver installed in your system.\n    \n    Parameters : \n    \n    path : Allows you specify the main directory name in which the images are downloaded\n    \n    limit : Denotes number of images that you want to download.\n    \n    format : Denotes the format/extension of the image that you want to download.\n    \n    \"\"\"\n    \n    if not os.path.exists(path):\n        os.makedirs(path)\n    \n    #importing the library\n    from google_images_download import google_images_download  \n    #class instantiation\n    response = google_images_download.googleimagesdownload()   \n    arguments = {\"keywords\":keyword,\n                 \"limit\":limit,\n                 \"size\":\"medium\",\n                 \"output_directory\":path}\n    paths = response.download(arguments)\n    print(paths) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# img_download(\n#     path=\"./\",\n#     limit=100,\n#     keyword=\"dew plants,fogsmog sky,frost plants,glaze trees,hail,lightning sky,rain streets,rain,rainbow sky,rime trees,sandstorm weather,snow weather\",\n#     format=\"jpg\"\n# )\nfrom bing_image_downloader import downloader\ndownloader.download(\"snow weather\", limit=100)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T20:48:12.918637Z","iopub.execute_input":"2022-05-17T20:48:12.918991Z","iopub.status.idle":"2022-05-17T20:50:20.085459Z","shell.execute_reply.started":"2022-05-17T20:48:12.918949Z","shell.execute_reply":"2022-05-17T20:50:20.084578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('./model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"src = \"./dew plants/dew plants\" # Folder to copy images from\n%pylab inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nc=0\nimport os\nos.chdir(\"./dataset/snow weather\")\n# os.listdir()\nfor imgg in  os.listdir():\n    try:\n        img = mpimg.imread(imgg)\n        imgplot = plt.imshow(img)\n        plt.show()\n        c=c+1\n    except:\n        continue\n    #c=c+1\n    #if c == 20:\n       # break\n#     print(imgg)\nprint(c)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T20:50:20.087495Z","iopub.execute_input":"2022-05-17T20:50:20.087808Z","iopub.status.idle":"2022-05-17T20:51:16.277259Z","shell.execute_reply.started":"2022-05-17T20:50:20.087764Z","shell.execute_reply":"2022-05-17T20:51:16.276329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport shutil\n# os.chdir('../input/nn22-weather-analysis-using-image-recognition/Dataset/Train/dew')\nsrc = \"../input/nn22-weather-analysis-using-image-recognition/Dataset/Train/dew\" # Folder to copy images from\n# # os.listdir()\nto_dir = './dataset/Dew Drop Plant'\nallFileNames = os.listdir(src)\ntrain_FileNames = ['../input/nn22-weather-analysis-using-image-recognition/Dataset/Train/dew'+'/'+ name for name in allFileNames]\n# os.chdir(\"/kaggle/working/dataset/Dew Drop Plant\")\n\nfor name in train_FileNames:\n    shutil.copy(name, \"./dataset/Dew Drop Plant\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# for name in train_FileNames:\n#     shutil.copy(name, \"./val\")\n# import os\n# print(os.listdir(\"../input/nn22-weather-analysis-using-image-recognition/Dataset/Train\"))\n# # !ls\nsrc = \"../input/nn22-weather-analysis-using-image-recognition/Dataset/Train/dew\" # Folder to copy images from\n# # os.listdir()\nto_dir = './dataset/Dew Drop Plant'\nallFileNames = os.listdir(src)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_FileNames = ['../input/nn22-weather-analysis-using-image-recognition/Dataset/Train/dew'+'/'+ name for name in allFileNames]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nfor name in train_FileNames:\n    shutil.copy(name, \"./dataset/Dew Drop Plant\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install --upgrade tensorflow\n# !pip install --upgrade Keras\nimport tensorflow as tf\nimport keras\n# !pip uninstall --yes keras\n# !pip install Keras==2.2.4\nprint(keras.__version__)\nprint(tf.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\n# import numpy as np\n# import os\n# import copy\nimport tensorflow as tf\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# from sklearn.metrics import classification_report,confusion_matrix\nimport keras\n# from keras.models import Sequential, Model,load_model\n# # from keras.preprocessing import image\n# import random\n# import numpy as np\n# from keras.layers import InputSpec,Layer,Input, Dense, BatchNormalization,Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation, Lambda, GlobalAveragePooling2D\n# # from keras.layers.normalization import BatchNormalization\n# from keras import backend as K\n\nimport os\nimport keras.backend as K\n\nfrom keras import initializers\nfrom keras.layers import Input,Layer,InputSpec\nfrom keras.layers import Dense\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import AveragePooling2D\nfrom keras.layers import ZeroPadding2D\nfrom keras.layers import Flatten\nfrom keras.layers import Activation\nfrom keras.layers import add\nfrom keras.layers import BatchNormalization\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import GlobalMaxPooling2D\n\nfrom keras.models import Model\n# from keras.engine import get_source_inputs\n\n# from keras.utils import get_source_inputs\n\n\n# from keras.utils.data_utils import get_file\n# from keras_applications.imagenet_utils import _obtain_input_shape\ncategories = ['dew','fogsmog','frost','glaze','hail','lightning','rain','rainbow','rime','sandstorm','snow']\ndirectory=\"../input/nn22-weather-analysis-using-image-recognition/Dataset/Train\"\n#Now we can easily fetch our train and validation data.\ndata=[]\nfor category in categories:\n    folder = os.path.join(directory,category)\n    label=categories.index(category)\n    for img in os.listdir(folder):\n        img_path = os.path.join(folder,img)\n        #print(img_path)\n        img_arr= cv2.imread(img_path)\n        if img_arr is not None:\n            img_arr= (img_arr)[...,::-1]\n            #, alpha=0,beta=255\n            img_arr=cv2.normalize(img_arr, None, alpha=0,beta=255,norm_type=cv2.NORM_MINMAX)\n            img_arr= cv2.resize(img_arr,(224,224))\n            data.append([img_arr,label])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install keras_applications","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"new code\n","metadata":{}},{"cell_type":"code","source":"import random\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam ,SGD\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras.initializers import glorot_uniform\nfrom keras import backend as K\nfrom keras import layers\n# !pip3 install keras_applications\nfrom keras_applications.imagenet_utils import _obtain_input_shape\nrandom.shuffle(data)\nx=[]\ny=[]\nfor features ,labels in data:\n    x.append(features)\n    y.append(labels)\ny = np.array(y)\nx = np.array(x)\n# input split\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(x, y,test_size=0.2, random_state= 8) \ntrain_generator = ImageDataGenerator(\n     rotation_range = 40, # augmention of images to avoid overfitting\n     shear_range = 0.2,\n     zoom_range = 0.2,\n     horizontal_flip = True,\n    #newwwwwwwwwwwwwwwwwwwwwwwwwwwww\n#     shear_range = 0.2,\n#     rotation_range=40,\n#     zoom_range=.2,\n#     horizontal_flip=True\n#     rotation_range=30,  # rotation\n#       fill_mode='nearest'\n#     width_shift_range=0.2,  # horizontal shift\n#     height_shift_range=0.2,\n#     zoom_range=0.2,  # zoom\n#     horizontal_flip=True,  # horizontal flip\n#     brightness_range=[0.2,1.2],\n    #horizontal_flip=True,\n    #vertical_flip=True,\n    #rotation_range=15,\n)\ntrain_generator.fit(X_train)\n# generator = train_generator.flow(X_train, y_train,shuffle=False)\n\n# (width_shift_range=[-200,200]\n\n\nWEIGHTS_PATH_NO_TOP = '../input/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n\ndef identity_block(input_tensor, kernel_size, filters, stage, block):\n    \"\"\"The identity block is the block that has no conv layer at shortcut.\n    # Arguments\n        input_tensor: input tensor\n        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n        filters: list of integers, the filterss of 3 conv layer at main path\n        stage: integer, current stage label, used for generating layer names\n        block: 'a','b'..., current block label, used for generating layer names\n    # Returns\n        Output tensor for the block.\n    \"\"\"\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters2, kernel_size,\n               padding='same', name=conv_name_base + '2b')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n\n    x = layers.add([x, input_tensor])\n    x = Activation('relu')(x)\n    return x\n\n\ndef conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n    \"\"\"conv_block is the block that has a conv layer at shortcut\n    # Arguments\n        input_tensor: input tensor\n        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n        filters: list of integers, the filterss of 3 conv layer at main path\n        stage: integer, current stage label, used for generating layer names\n        block: 'a','b'..., current block label, used for generating layer names\n    # Returns\n        Output tensor for the block.\n    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n    And the shortcut should have strides=(2,2) as well\n    \"\"\"\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    x = Conv2D(filters1, (1, 1), strides=strides,\n               name=conv_name_base + '2a')(input_tensor)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters2, kernel_size, padding='same',\n               name=conv_name_base + '2b')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n\n    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n                      name=conv_name_base + '1')(input_tensor)\n    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n\n    x = layers.add([x, shortcut])\n    x = Activation('relu')(x)\n    return x\n\n\ndef ResNet50(include_top=True, weights='imagenet',\n             input_tensor=None, input_shape=None,\n             pooling=None,\n             classes=1000):\n    \"\"\"Instantiates the ResNet50 architecture.\n    Optionally loads weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format=\"channels_last\"` in your Keras config\n    at ~/.keras/keras.json.\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n    # Arguments\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization)\n            or \"imagenet\" (pre-training on ImageNet).\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or `(3, 224, 244)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 197.\n            E.g. `(200, 200, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=197,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n\n    x = ZeroPadding2D((3, 3))(img_input)\n    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n\n    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n\n    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n\n    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n\n    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n\n    if include_top:\n        x = Flatten()(x)\n        x = Dense(classes, activation='softmax', name='fc1000')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = Model(inputs, x, name='resnet50')\n\n    # load weights\n    if weights == 'imagenet':\n        model.load_weights('../input/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n        if K.backend() == 'theano':\n            layer_utils.convert_all_kernels_in_model(model)\n\n        if K.image_data_format() == 'channels_first':\n            if include_top:\n                maxpool = model.get_layer(name='avg_pool')\n                shape = maxpool.output_shape[1:]\n                dense = model.get_layer(name='fc1000')\n                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n\n            if K.backend() == 'tensorflow':\n                warnings.warn('You are using the TensorFlow backend, yet you '\n                              'are using the Theano '\n                              'image data format convention '\n                              '(`image_data_format=\"channels_first\"`). '\n                              'For best performance, set '\n                              '`image_data_format=\"channels_last\"` in '\n                              'your Keras config '\n                              'at ~/.keras/keras.json.')\n    return model\nbase_model = ResNet50(include_top=False, weights='imagenet',pooling='avg')\n# headModel = base_model.output\n# # headModel = Flatten()(headModel)\n# # headModel = Dense(256, activation='relu', name='fc1',kernel_initializer=glorot_uniform(seed=0))(headModel)\n# # headModel = Dense(128, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(headModel)\n# # headModel = Dense(11,activation='softmax', name='fc3',kernel_initializer=glorot_uniform(seed=0))(headModel)\n# # model = Model(inputs=base_model.input, outputs=headModel)\n# headModel = Dense(256, activation='relu', name='fc1')(headModel)\n# headModel = Dense(128, activation='relu', name='fc2')(headModel)\n# headModel = Dense(11,activation='softmax', name='fc3')(headModel)\n# model = Model(base_model.input, headModel)\n# base_model.load_weights(\"../input/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n# model.summary()\n\nheadModel = base_model.output\nheadModel = Flatten()(headModel)\n# headModel=Dense(256, activation='relu', name='fc1',kernel_initializer=glorot_uniform(seed=0))(headModel)\nheadModel=Dense(128, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(headModel)\nheadModel = Dense(11,activation='softmax', name='fc3',kernel_initializer=glorot_uniform(seed=0))(headModel)\nmodel = Model(inputs=base_model.input, outputs=headModel)\n\n# train_generator.fit(X_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# opt = SGD(learning_rate=0.001, momentum=0.9,decay=0.0002\n# opt = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n#optim = RMSprop(learning_rate=0.00001)\n# opt = SGD(learning_rate=0.0001, momentum=0.9, decay=0.0001 / 100)\n# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n#     initial_learning_rate=1e-2,\n#     decay_steps=10000,\n#     decay_rate=0.9)\n# ptimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\nopt = Adam(learning_rate=0.001)\nmodel.compile(optimizer = opt , loss =\"sparse_categorical_crossentropy\" , metrics = ['accuracy'])\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n\nearly = EarlyStopping(patience=10,monitor='val_loss', mode='min', verbose=1)\nmc = ModelCheckpoint('./best_model.h5', monitor='val_accuracy', mode='max',save_weights_only=True, save_best_only=True)\nX_train = np.array(X_train)\nX_val = np.array(X_val)\ny_val = np.array(y_val)\ny_train = np.array(y_train)\n\n# train_generator = train_datagen.flow_from_directory(\n#         '../input/nn22-weather-analysis-using-image-recognition/Dataset/Train',\n#         target_size=(img_height, img_width),\n#         batch_size=32,\n#         class_mode='categorical')\n#train_generator.flow(X_train,y_train,shuffle=False, batch_size=32)\n# ,steps_per_epoch=len(X_train)\nhist = model.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=100,verbose=1,callbacks=[early,mc],batch_size=50)\n#history = model.fit(np.array(X_train), np.array(y_train),\n                          #validation_data=(np.array(X_val), np.array(y_val)),epochs=30)\n#hist=model.fit(generator,validation_data=(X_val, y_val),epochs=100,verbose=1,batch_size=128,callbacks=[early,mc])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n#fit_params={'early_stopping_rounds':20,'eval_set':[(x,y)]}\nscores = cross_val_score(model, x, y, cv=5)\nscores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport pandas as pd\n#from keras.preprocessing import image\ntest_images=[]\ntest_names=[]\ndiff_image=\"\"\nmodel.load_weights(\"./best_model.h5\")\nfor img in os.listdir(\"../input/nn22-weather-analysis-using-image-recognition/Dataset/Test\"):\n    path=\"../input/nn22-weather-analysis-using-image-recognition/Dataset/Test/\"+img\n    img_arr=cv2.imread(path)\n    try:\n        img_arr= (img_arr)[...,::-1]\n        #\n        img_arr=cv2.normalize(img_arr, None, alpha=0,beta=255,norm_type=cv2.NORM_MINMAX)\n        img_arr= cv2.resize(img_arr,(224,224))\n        test_images.append(img_arr)\n        test_names.append(img)\n    except:\n        diff_image=img\n        continue\nx=np.array(test_images)\n#print(x)\npredict_test=model.predict(x)\n_classes=np.argmax(predict_test,axis=1)\nprint(_classes)\ntest_names.append(diff_image)\ntest_labels=_classes.tolist()\ntest_labels.append(10)\nprint(len(test_names))\nprint(len(test_labels))\ndf_test = pd.DataFrame()\ndf_test['image_name'] = test_names\ndf_test['label'] = test_labels\ndf_test.to_csv('file.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_json = model.to_json()\nwith open(\"./model.json\",\"w\") as json_file:\n    json_file.write(model_json)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}